{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e425b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad464b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_no_folds(scenario_dir_path, dataset_type):\n",
    "    # make dict to store data\n",
    "    storage_list = list()\n",
    "    # make paths for the specified dataset\n",
    "    train_annotations_dir = Path(scenario_dir_path, dataset_type, \"annotations\")\n",
    "    train_physiology_dir = Path(scenario_dir_path, dataset_type, \"physiology\")\n",
    "    # sort contents of dirs, so that physiology and annotations are in the same order  \n",
    "    train_physiology_files = sorted(Path(train_physiology_dir).iterdir())\n",
    "    train_annotation_files = sorted(Path(train_annotations_dir).iterdir())\n",
    "    # iterate over annotation and physiology files\n",
    "    for physiology_file_path, annotations_file_path in zip(train_physiology_files, train_annotation_files):\n",
    "        # make sure that we load corresponding physiology and annotations\n",
    "        assert physiology_file_path.name == annotations_file_path.name, \"Order mismatch\"\n",
    "        # load data from files\n",
    "        df_physiology = pd.read_csv(physiology_file_path, index_col=\"time\")\n",
    "        df_annotations = pd.read_csv(annotations_file_path, index_col=\"time\")\n",
    "        # store data\n",
    "        storage_list.append((annotations_file_path.name, df_physiology, df_annotations))\n",
    "    return storage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1198e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_folds(scenario_dir_path, dataset_type):\n",
    "    # make dict to store data\n",
    "    storage_dict = dict()\n",
    "    # iterate over the scenario directory\n",
    "    for fold_dir in Path(scenario_dir_path).iterdir():\n",
    "        # make paths for current fold\n",
    "        train_annotations_dir = Path(fold_dir, f\"{dataset_type}/annotations/\")\n",
    "        train_physiology_dir = Path(fold_dir, f\"{dataset_type}/physiology/\")\n",
    "        # make key in a dict for current fold \n",
    "        storage_dict.setdefault(fold_dir.name, list())\n",
    "        # sort contents of dirs, so that physiology and annotations are in the same order  \n",
    "        train_physiology_files = sorted(Path(train_physiology_dir).iterdir())\n",
    "        train_annotation_files = sorted(Path(train_annotations_dir).iterdir())\n",
    "        # iterate over annotation and physiology files\n",
    "        for physiology_file_path, annotations_file_path in zip(train_physiology_files, train_annotation_files):\n",
    "            # make sure that we load corresponding physiology and annotations\n",
    "            assert physiology_file_path.name == annotations_file_path.name, \"Order mismatch\"\n",
    "            # load data from files\n",
    "            df_physiology = pd.read_csv(physiology_file_path, index_col=\"time\")\n",
    "            df_annotations = pd.read_csv(annotations_file_path, index_col=\"time\")\n",
    "            # store data\n",
    "            storage_dict[fold_dir.name].append((annotations_file_path.name, df_physiology, df_annotations))\n",
    "    return storage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f9dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(modality, annotations, physiology, test=False):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    # plot train physiology with annotations range \n",
    "    plt.subplot(211)\n",
    "    plt.plot(physiology.index, physiology[modality])\n",
    "    plt.axvspan(annotations.index[0], annotations.index[-1], color='green', alpha=0.3)\n",
    "    plt.xlim(left=physiology.index[0], right=physiology.index[-1])\n",
    "    plt.title(f\"{test * 'Test' + (not test) * 'Training'} data\", fontsize=20)\n",
    "    plt.ylabel(\"Signal value\", fontsize=16)\n",
    "    plt.xlabel(\"Time\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    # plot train annotations\n",
    "    plt.subplot(212)\n",
    "    plt.plot(annotations.index, annotations['arousal'], label='arousal - train')\n",
    "    plt.plot(annotations.index, annotations['valence'], label='valence - train')\n",
    "    plt.xlim(left=physiology.index[0], right=physiology.index[-1])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.ylabel(\"Annotation value\", fontsize=16)\n",
    "    plt.xlabel(\"Time\", fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a05d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "\n",
    "def plot_eda(data, fs=1000):\n",
    "    # Process the raw EDA signal\n",
    "    preprocess = nk.eda_clean(data, sampling_rate=fs)\n",
    "    signals, info = nk.eda_process(preprocess, sampling_rate=fs)\n",
    "    # Extract clean EDA and SCR features\n",
    "    cleaned = signals[\"EDA_Phasic\"]\n",
    "    features = [info[\"SCR_Onsets\"], info[\"SCR_Peaks\"], info[\"SCR_Recovery\"]]\n",
    "    # Visualize SCR features in cleaned EDA signal\n",
    "    plot = nk.events_plot(features, cleaned, color=['red', 'blue', 'orange'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44776e51",
   "metadata": {},
   "source": [
    "### helpers to calculate phasic and tonic components"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2003106c",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "raw",
   "id": "104a3c1c",
   "metadata": {},
   "source": [
    "# Reshape a numpy array 'a' of shape (n, x) to form shape((n - window_size), window_size, x))\n",
    "def rolling_window(a, window, step_size):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1 - step_size + 1, window)\n",
    "    strides = a.strides + (a.strides[-1] * step_size,)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bbc159a",
   "metadata": {},
   "source": [
    "def filterTonicEDA(signal, coarsest=2):\n",
    "    X        = dct(signal - np.mean(signal)) # discrete cosine transform\n",
    "    absX     = np.abs(X)   # keep magnitude only\n",
    "    absX[::-1].sort()      # sort in reverse order (descending)\n",
    "    absX[coarsest:] = 0    # remove components with less impact\n",
    "    tonic    = idct(absX)  # inverse discrete cosine transform\n",
    "    return signal - tonic, tonic # return phasic and tonic component"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9906b02",
   "metadata": {},
   "source": [
    "# pre-processing like in Perusquia, 2019: skin condunctance from neck and hand\n",
    "\n",
    "fs_gsr     = 1000 # sampling frequency of EDA data\n",
    "step_width = 1    # of sliding window\n",
    "winDur     = 0.1  # duration in seconds of sliding window\n",
    "N_win      = int(np.round(fs_gsr * winDur)) # duration of sliding window in samples\n",
    "smoothing_fcn = np.mean # I could call np.mean(..) later but apparently it is faster this way\n",
    "winLen     = 1001 # sample duration of the savitzky golay filter\n",
    "order      = 1    # order of the savitzky golay filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69cdd5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c3ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "Loading test data\n"
     ]
    }
   ],
   "source": [
    "# specify scenario path\n",
    "scenario_dir = \"../data/scenario_1\"\n",
    "\n",
    "# train data\n",
    "print(\"Loading train data\")\n",
    "train = load_data_no_folds(scenario_dir, \"train\")\n",
    "\n",
    "# test data\n",
    "print(\"Loading test data\")\n",
    "test = load_data_no_folds(scenario_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d79211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sub_11_vid_11.csv',\n",
       "          ecg     bvp     gsr     rsp     skt  emg_zygo  emg_coru  emg_trap\n",
       " time                                                                      \n",
       " 0      0.734  36.641  41.599  34.773  25.758     6.549     6.467   148.886\n",
       " 1      0.754  36.450  41.606  34.773  25.761     6.508     6.548   158.771\n",
       " 2      0.738  36.583  41.591  34.763  25.761     6.427     6.508   172.897\n",
       " 3      0.712  36.699  41.653  34.763  25.761     6.385     6.467   185.928\n",
       " 4      0.672  36.767  41.603  34.754  25.757     6.425     6.467   193.661\n",
       " ...      ...     ...     ...     ...     ...       ...       ...       ...\n",
       " 75046  0.760  36.379  36.496  37.512  25.694     5.480     6.714    27.780\n",
       " 75047  0.757  36.668  36.508  37.522  25.691     5.400     6.754    27.700\n",
       " 75048  0.764  36.163  36.430  37.531  25.691     5.480     6.754    27.658\n",
       " 75049  0.770  36.273  36.430  37.532  25.698     5.440     6.714    27.455\n",
       " 75050  0.761  36.370  36.437  37.532  25.698     5.399     6.713    27.412\n",
       " \n",
       " [75051 rows x 8 columns],\n",
       "        valence  arousal\n",
       " time                   \n",
       " 0        5.000    5.000\n",
       " 50       5.000    5.000\n",
       " 100      5.000    5.000\n",
       " 150      5.000    5.000\n",
       " 200      5.000    5.000\n",
       " ...        ...      ...\n",
       " 74850    6.821    3.862\n",
       " 74900    6.821    3.862\n",
       " 74950    6.821    3.862\n",
       " 75000    6.821    3.862\n",
       " 75050    6.821    3.862\n",
       " \n",
       " [1502 rows x 2 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name, data, label] = train[2]\n",
    "name, data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da713f",
   "metadata": {},
   "source": [
    "### Look at all the GSR data and their ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a8d0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (name, data, label) in train:\n",
    "    print(name)\n",
    "    plot_data('gsr', label, data, test=False)\n",
    "    plt.figure()\n",
    "    plot_eda(data.gsr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b0b5a",
   "metadata": {},
   "source": [
    "### Extract video numbers and order from all loaded data\n",
    "\n",
    "This allows us to look at data per video to identify potential similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cf500",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_vid = list()\n",
    "\n",
    "for (name, data, label) in train:\n",
    "    parts = name.split('_')\n",
    "    sub_vid.append(\n",
    "        (\n",
    "            int(parts[1]), # get participant number\n",
    "            int(parts[-1].split('.')[0])) # get video number\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(sub_vid, columns=['participant', 'video'])\n",
    "videos = sorted(df.video.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd857c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for v in videos:\n",
    "    print(f\"Video {v}\")\n",
    "    for idx in df[df.video == v].index:\n",
    "        (name, data, label) = train[idx]\n",
    "        print(name)\n",
    "        plot_data('gsr', label, data, test=False)\n",
    "        plt.figure()\n",
    "        plot_eda(data.gsr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2910a2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify scenario path\n",
    "scenario_dir = \"../data/scenario_4\"\n",
    "\n",
    "# train data\n",
    "print(\"Loading train data\")\n",
    "load_data_with_folds(scenario_dir, \"train\")\n",
    "\n",
    "# test data\n",
    "print(\"Loading test data\")\n",
    "load_data_with_folds(scenario_dir, \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
